{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zipfile.ZipFile(\"archive (1).zip\").extractall(\"dataset\")#Unzipping data into dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "admission_predict=r\"C:\\Users\\saatv\\OneDrive\\Desktop\\Graduate-Admission-Prediction\\dataset\\Admission_Predict_Ver1.1.csv\"\n",
    "df=pd.read_csv(admission_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)#Since output is a number, it is a regression problem(chance of admit to be predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "495         496        332          108                  5  4.5   4.0  9.02   \n",
       "496         497        337          117                  5  5.0   5.0  9.87   \n",
       "497         498        330          120                  5  4.5   5.0  9.56   \n",
       "498         499        312          103                  4  4.0   5.0  8.43   \n",
       "499         500        327          113                  4  4.5   4.5  9.04   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "495         1              0.87  \n",
       "496         1              0.96  \n",
       "497         1              0.93  \n",
       "498         0              0.73  \n",
       "499         0              0.84  \n",
       "\n",
       "[500 rows x 9 columns]>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()#to check duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Serial No.',inplace=True)#dropping serial no. column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,0:-1]#all rows and all columns except the last one\n",
    "y=df.iloc[:,-1]#all rows of the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "495        332          108                  5  4.5   4.0  9.02         1\n",
       "496        337          117                  5  5.0   5.0  9.87         1\n",
       "497        330          120                  5  4.5   5.0  9.56         1\n",
       "498        312          103                  4  4.0   5.0  8.43         0\n",
       "499        327          113                  4  4.5   4.5  9.04         0\n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "495    0.87\n",
       "496    0.96\n",
       "497    0.93\n",
       "498    0.73\n",
       "499    0.84\n",
       "Name: Chance of Admit , Length: 500, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)#20% in testing and 80% in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>310</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>318</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>300</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>300</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>322</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>307</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>321</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>326</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>300</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "238        310          104                  3  2.0   3.5  8.37         0\n",
       "438        318          110                  1  2.5   3.5  8.54         1\n",
       "475        300          101                  3  3.5   2.5  7.88         0\n",
       "58         300           99                  1  3.0   2.0  6.80         1\n",
       "380        322          104                  3  3.5   4.0  8.84         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "255        307          110                  4  4.0   4.5  8.37         0\n",
       "72         321          111                  5  5.0   5.0  9.45         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "235        326          111                  5  4.5   4.0  9.23         1\n",
       "37         300          105                  1  1.0   2.0  7.80         0\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4       , 0.42857143, 0.5       , ..., 0.57142857, 0.50320513,\n",
       "        0.        ],\n",
       "       [0.56      , 0.64285714, 0.        , ..., 0.57142857, 0.55769231,\n",
       "        1.        ],\n",
       "       [0.2       , 0.32142857, 0.5       , ..., 0.28571429, 0.34615385,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.74038462,\n",
       "        1.        ],\n",
       "       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.77884615,\n",
       "        1.        ],\n",
       "       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.32051282,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled#Normalized numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(7,activation='relu',input_dim=7))#since there are 7 columns(7 features)\n",
    "model.add(Dense(5,activation='relu'))\n",
    "model.add(Dense(3,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m40\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m18\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m4\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118</span> (472.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m118\u001b[0m (472.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118</span> (472.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m118\u001b[0m (472.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4434 - val_loss: 0.4227\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3595 - val_loss: 0.3479\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3001 - val_loss: 0.2712\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2204 - val_loss: 0.1959\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1635 - val_loss: 0.1248\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1039 - val_loss: 0.0669\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0525 - val_loss: 0.0301\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0240 - val_loss: 0.0139\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0109 - val_loss: 0.0105\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0082 - val_loss: 0.0102\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0087 - val_loss: 0.0090\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0075 - val_loss: 0.0087\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0075 - val_loss: 0.0084\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0069 - val_loss: 0.0081\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0067 - val_loss: 0.0071\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0061 - val_loss: 0.0067\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0065 - val_loss: 0.0066\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0068 - val_loss: 0.0064\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0061 - val_loss: 0.0063\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0056 - val_loss: 0.0061\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0060 - val_loss: 0.0054\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0054 - val_loss: 0.0052\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0056 - val_loss: 0.0051\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0034 - val_loss: 0.0037\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train_scaled,y_train,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7741213101291925"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)#Should be 1 for a perfect fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22be46fd370>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAw3klEQVR4nO3de3Bc5X3/8c/Zqy7WxbJsGWPZEUkaOxgIyA01l5A0QRlC0tLkl7rQYNJCi8ulGE8bcN1foZ6mptOEksxgBxICQwngtqEtbd02SkmIiTMBhE0d4NeQxiBh5AjJtnZ129t5fn+cs6tdXey9H8l6v2YWac+e3f3uIw/66DnPxTLGGAEAAHjE53UBAABgYSOMAAAATxFGAACApwgjAADAU4QRAADgKcIIAADwFGEEAAB4ijACAAA8FfC6gHzYtq23335bDQ0NsizL63IAAEAejDGKRqNasWKFfL7Z+z/mRRh5++231d7e7nUZAACgCH19fVq5cuWsj8+LMNLQ0CDJ+TCNjY0eVwMAAPIRiUTU3t6e+T0+m3kRRtKXZhobGwkjAADMM6caYsEAVgAA4CnCCAAA8BRhBAAAeIowAgAAPEUYAQAAniKMAAAATxFGAACApwgjAADAU4QRAADgKcIIAADwFGEEAAB4ijACAAA8NS82yquUp156Swf7TuiT567QBztavC4HAIAFaUH3jDzz/wb06I/e1KEjw16XAgDAgrWgw0jrorAkaWgk5nElAAAsXAv6Ms35sRdU4/+Rwu98TNIar8sBAGBBWtA9Ix8Y+jfdGXxSy44f8LoUAAAWrAUdRqy6JZIk38RxjysBAGDhWtBhxN/QKkkKxQkjAAB4ZUGHkbAbRmoTJ7wtBACABWxBh5G6pmWSpEV2RBOJlMfVAACwMC3oMFLb7ISRFmtEx0bjHlcDAMDCtKDDiFXnrLrabEU1NEIYAQDACws6jMidTdOiqIZGJjwuBgCAhWmBhxGnZ6TGSujEMEvCAwDghYUdRkKLlLSCkqSx4Xc8LgYAgIVpYYcRy9JYoEmSNBEZ8LgYAAAWpoUdRiTFQ82SpFR00NtCAABYoBZ8GEnVOONG7NFjHlcCAMDCtODDiGqdMGKND3lcCAAAC1NRYWTXrl3q6OhQTU2NOjs7tW/fvrye98Mf/lCBQEAf+MAHinnbivDVO9N7A7ET3hYCAMACVXAY2bNnj7Zs2aLt27frwIEDuvTSS3XFFVeot7f3pM8bHh7Wpk2b9NGPfrToYish2LhUkhSOn/C2EAAAFqiCw8i9996r66+/XjfccIPWrl2r++67T+3t7dq9e/dJn3fjjTfqmmuu0YYNG4outhJqGp3N8hrNsMbiSY+rAQBg4SkojMTjcfX09KirqyvneFdXl/bv3z/r8x5++GH97//+r+66667iqqygsNsz0qwRloQHAMADgUJOHhwcVCqVUltbW87xtrY2HT16dMbnvP7667rzzju1b98+BQL5vV0sFlMsFsvcj0QihZRZEKvO6RlpsaI6NhpXe0tdxd4LAABMV9QAVsuycu4bY6Ydk6RUKqVrrrlGf/7nf65f+qVfyvv1d+7cqaampsytvb29mDLzU7dYktRsjWhoNHaKkwEAQLkVFEZaW1vl9/un9YIMDAxM6y2RpGg0qhdffFG33HKLAoGAAoGAduzYoZdfflmBQEDPPPPMjO+zbds2DQ8PZ259fX2FlFmYrM3yBrlMAwBA1RV0mSYUCqmzs1Pd3d36jd/4jczx7u5u/fqv//q08xsbG3Xo0KGcY7t27dIzzzyjf/iHf1BHR8eM7xMOhxUOhwsprXjuOiO1VlyRyLCkCvbCAACAaQoKI5K0detWXXvttVq/fr02bNigBx98UL29vdq8ebMkp1fjyJEjevTRR+Xz+bRu3bqc5y9btkw1NTXTjnsm3KCUFZDfJDV2gs3yAACotoLDyMaNGzU0NKQdO3aov79f69at0969e7V69WpJUn9//ynXHJlTLEsTwWbVxweViBJGAACoNssYY7wu4lQikYiampo0PDysxsbGsr/+iS+vV3P0df3Vsr/SHTdtLvvrAwCwEOX7+5u9aSSZ9P40Y+xPAwBAtRFGJFnujBr/BDv3AgBQbYQRSYFFThgJxk5oHly1AgDgtEIY0eSS8I0motF4yuNqAABYWAgjkoINzpLwi60RDY2wCisAANVEGJEyq7AuVlRDo6zCCgBANRFGpMkl4a0oO/cCAFBlhBEpsyR8szWiY2yWBwBAVRFGJKnOCSNslgcAQPURRqTMZZo6K6bhSMTjYgAAWFgII5IUbpBtOdv0xCLsTwMAQDURRiTJshQLNUuSkiMsCQ8AQDURRlx2zWLn6yhhBACAaiKMuEytM27EN87+NAAAVBNhxOVP708TP87+NAAAVBFhxJVeEr7RjioykfS4GgAAFg7CiCuwKL0/TZT9aQAAqCLCSFp6fxorqmPsTwMAQNUQRtJqWYUVAAAvEEbS6BkBAMAThJE0d3+axdYIY0YAAKgiwkhaOowoqiF6RgAAqBrCSJp7mabeimk4GvW4GAAAFg7CSFq4MbNZXjw66HExAAAsHISRNMtSMtwsif1pAACoJsJIFtud3mtG2Z8GAIBqIYxk8dWl96c5JttmfxoAAKqBMJIl4O5P02SiGh5PeFwNAAALA2Eki4/pvQAAVB1hJJt7maaFVVgBAKgawkg2N4w0WyM6NsoqrAAAVANhJFvd5GZ5XKYBAKA6CCPZsntG2LkXAICqIIxkS48ZoWcEAICqIYxkq10sSVpsEUYAAKgWwkg2d8zIImtCwyMjHhcDAMDCQBjJFm6SsZwmSUbZnwYAgGogjGTz+ZQKO5dqzBhhBACAaiCMTOVeqvGNH5cx7E8DAEClEUamSC8J32CiiownPa4GAIDTH2FkCl+9M73XmVHDKqwAAFQaYWSq2vRmeSPsTwMAQBUQRqaqcwawNlsjrDUCAEAVEEamyvSMsHMvAADVQBiZKmt/mqERxowAAFBphJGp0jv3siQ8AABVQRiZyr1M08wAVgAAqoIwMpXbM7LYYswIAADVQBiZyu0ZadKojkUnPC4GAIDTH2Fkqlpnaq/fMkqMHve4GAAATn+EkakCIdmhRZIke2yI/WkAAKgwwshM3Om9DXZU0Rj70wAAUEmEkRn4sgexjjCIFQCASiKMzCRrfxrWGgEAoLIIIzNxe0aamd4LAEDFEUZmku4ZYUl4AAAqjjAykzou0wAAUC2EkZnUcpkGAIBqIYzMJKtnhDACAEBlEUZmkjW1l8s0AABUFmFkJlkDWI+NMoAVAIBKIozMJHsAa5QwAgBAJRFGZuL2jISthMbGouxPAwBABRFGZhKql/GHJEn1yYhG4ymPCwIA4PRFGJmJZcnKHjfC/jQAAFQMYWQ2WUvCDzGIFQCAiiGMzKZuiSTWGgEAoNIII7OpXSzJXWuEyzQAAFQMYWQ27E8DAEBVFBVGdu3apY6ODtXU1Kizs1P79u2b9dznnntOF198sZYsWaLa2lqtWbNGf/M3f1N0wVVTO7kKKwufAQBQOYFCn7Bnzx5t2bJFu3bt0sUXX6wHHnhAV1xxhV599VWtWrVq2vn19fW65ZZbdO6556q+vl7PPfecbrzxRtXX1+v3f//3y/IhKiIzgHVEh+gZAQCgYixT4IpeF154oS644ALt3r07c2zt2rW66qqrtHPnzrxe49Of/rTq6+v1t3/7t3mdH4lE1NTUpOHhYTU2NhZSbvEOfEv655v0/dR5euSsL+mR3/lgdd4XAIDTRL6/vwu6TBOPx9XT06Ourq6c411dXdq/f39er3HgwAHt379fl1122aznxGIxRSKRnFvVZU3tZTYNAACVU1AYGRwcVCqVUltbW87xtrY2HT169KTPXblypcLhsNavX6+bb75ZN9xww6zn7ty5U01NTZlbe3t7IWWWR9bUXmbTAABQOUUNYLUsK+e+MWbasan27dunF198UV/72td033336Yknnpj13G3btml4eDhz6+vrK6bM0mQNYGXRMwAAKqegAaytra3y+/3TekEGBgam9ZZM1dHRIUk655xz9Itf/EJ33323rr766hnPDYfDCofDhZRWfu5lmkZrXMlEXGPxpOpCBY/3BQAAp1BQz0goFFJnZ6e6u7tzjnd3d+uiiy7K+3WMMYrF5nhvQ02TjJzenmaNcqkGAIAKKfhP/a1bt+raa6/V+vXrtWHDBj344IPq7e3V5s2bJTmXWI4cOaJHH31UknT//fdr1apVWrNmjSRn3ZEvfelLuvXWW8v4MSrA55dV2yyNH88MYm1vqfO6KgAATjsFh5GNGzdqaGhIO3bsUH9/v9atW6e9e/dq9erVkqT+/n719vZmzrdtW9u2bdPhw4cVCAT07ne/W/fcc49uvPHG8n2KSqltkcaPu6uwzvGeHAAA5qmC1xnxgifrjEjSNz4mvfWCfj9+uy7/9PX67HoPZvUAADBPVWSdkQWndnIVVtYaAQCgMggjJ5O11ghhBACAyiCMnExd9mZ5hBEAACqBMHIytYsl0TMCAEAlEUZOJrtnZIwwAgBAJRBGToYBrAAAVBxh5GTSPSNcpgEAoGIIIyeT6RmJKjqRVCJle1wQAACnH8LIyWRN7ZWMjtM7AgBA2RFGTsa9TBOwbDVqjEGsAABUAGHkZAJhKVgvyR3Eys69AACUHWHkVDKDWJneCwBAJRBGTiW98Jk1wpgRAAAqgDByKm7PSLNGNEQYAQCg7Agjp1I7uQorPSMAAJQfYeRU0tN7rSg9IwAAVABh5FSyVmE9zgBWAADKjjByKpnLNCM6NprwuBgAAE4/hJFTyazCGtWx0ZjHxQAAcPohjJxKXfbU3oSMMR4XBADA6YUwcipZA1jjKVsjsaTHBQEAcHohjJxK7eQKrJJ0nHEjAACUFWHkVNyekRoroRrFWBIeAIAyI4ycSqhe8ockSS0MYgUAoOwII6diWVnjRpjeCwBAuRFG8pG1JDw9IwAAlBdhJB91k4NY6RkBAKC8CCP5qKNnBACASiGM5COzCitjRgAAKDfCSD6yxoywWR4AAOVFGMlHzmwawggAAOVEGMlHzgBWwggAAOVEGMlH1v40w+MJJVK2xwUBAHD6IIzkwx0z0mKNSJJOjDGIFQCAciGM5CMztdcJIwxiBQCgfAgj+XDDSJ0mFFZcQyOEEQAAyoUwko9wo+QLSJKaNULPCAAAZUQYyYdlZY0biWqIGTUAAJQNYSRf7oyaZmtExwkjAACUDWEkX+64kRbWGgEAoKwII/nK2SyPMAIAQLkQRvJVO7kKKwNYAQAoH8JIvrL2p2FqLwAA5UMYyVcdO/cCAFAJhJF8pXtG5Ozca4zxuCAAAE4PhJF81U72jMSStsbiKY8LAgDg9EAYyZfbM5LeLI8ZNQAAlAdhJF91kyuwSoQRAADKhTCSLzeM1GtcQSV1jEGsAACUBWEkX+EmyXKaq1lRHWN6LwAAZUEYyZfPJ9UuluSsNcL0XgAAyoMwUojMIFaWhAcAoFwII4Vwp/c2u2uNAACA0hFGCkHPCAAAZUcYKUSdM2akWYQRAADKhTBSiOyeEQawAgBQFoSRQmSWhB/RcXpGAAAoC8JIITKb5UV1YjyhlM1meQAAlIowUoi6yZ4RY8RaIwAAlAFhpBBuz8gSH/vTAABQLoSRQqTHjMjZuXeIJeEBACgZYaQQbs9Ig0blV0pDozGPCwIAYP4jjBSitlmSJYlVWAEAKBfCSCF8fjeQSM3WiAa5TAMAQMkII4Vyx420KKqhES7TAABQKsJIodJrjbA/DQAAZUEYKVTWWiPMpgEAoHSEkUJlrcLKbBoAAEpXVBjZtWuXOjo6VFNTo87OTu3bt2/Wc5966ildfvnlWrp0qRobG7Vhwwb953/+Z9EFe67W2bl3sRXVEJdpAAAoWcFhZM+ePdqyZYu2b9+uAwcO6NJLL9UVV1yh3t7eGc//wQ9+oMsvv1x79+5VT0+PPvKRj+hTn/qUDhw4UHLxnsj0jIzoxFhCiZTtcUEAAMxvljGmoN3eLrzwQl1wwQXavXt35tjatWt11VVXaefOnXm9xtlnn62NGzfqz/7sz/I6PxKJqKmpScPDw2psbCyk3PLreUT6l9v03dQFuiHxR3p++0e1rKHG25oAAJiD8v39XVDPSDweV09Pj7q6unKOd3V1af/+/Xm9hm3bikajamlpKeSt5w63Z2Spf1QSS8IDAFCqQCEnDw4OKpVKqa2tLed4W1ubjh49mtdrfPnLX9bo6Kh+8zd/c9ZzYrGYYrHJwaGRSKSQMisrvc6Iz9mfhum9AACUpqgBrJZl5dw3xkw7NpMnnnhCd999t/bs2aNly5bNet7OnTvV1NSUubW3txdTZmW4PSPNcnbuHWThMwAASlJQGGltbZXf75/WCzIwMDCtt2SqPXv26Prrr9ff/d3f6WMf+9hJz922bZuGh4czt76+vkLKrCx3nZF6OyqfbC7TAABQooLCSCgUUmdnp7q7u3OOd3d366KLLpr1eU888YQ+//nP6/HHH9eVV155yvcJh8NqbGzMuc0Z7tRen4ya2CwPAICSFTRmRJK2bt2qa6+9VuvXr9eGDRv04IMPqre3V5s3b5bk9GocOXJEjz76qCQniGzatElf+cpX9Cu/8iuZXpXa2lo1NTWV8aNUiT8o1TRJE8NqsVj4DACAUhUcRjZu3KihoSHt2LFD/f39Wrdunfbu3avVq1dLkvr7+3PWHHnggQeUTCZ188036+abb84cv+666/TII4+U/gm8ULdEmhh2VmHlMg0AACUpeJ0RL8ypdUYk6RuXS289rxvjt2uwvUvf/oPZL1EBALBQVWSdEbjqWyVJLVZEQ8ymAQCgJISRYqR37hX70wAAUCrCSDHqnJ6RJVZU0YmkYsmUxwUBADB/EUaK4V6mabWclWGPjya8rAYAgHmNMFIMdxXWZQFnfxpWYQUAoHiEkWK4l2lafc6S8IwbAQCgeISRYtQ7PSOL5VymOcbCZwAAFI0wUgz3Mk2j7YQRFj4DAKB4hJFiuJdpQiamWk1wmQYAgBIQRooRqpcCNZKc6b0sfAYAQPEII8WwrMylGvanAQCgNISRYrlhZIkV4TINAAAlIIwUyw0jLYpoiNk0AAAUjTBSLHcV1sVWVMe4TAMAQNEII8XK2p9mNJ7SeJz9aQAAKAZhpFjuZZqlmVVYuVQDAEAxCCPFqs/dn+YYg1gBACgKYaRY7mWaTM8I40YAACgKYaRYWbNpJDbLAwCgWISRYrmzaSb3p2HMCAAAxSCMFMu9TFNnRxVQkp4RAACKRBgpVm2zJEuStFgjjBkBAKBIhJFi+fxSXYskZ+EzpvYCAFAcwkgpMgufRZjaCwBAkQgjpcjMqGHnXgAAikUYKYW78Fn6Mo0xxuOCAACYfwgjpUhfplFEEwlbY+xPAwBAwQgjpUjvT+MfkcQqrAAAFIMwUgp34bPl7v40zKgBAKBwhJFSZHpG2J8GAIBiEUZK4YaRxXLCCNN7AQAoHGGkFO5lmiYzLEka5DINAAAFI4yUwu0ZWZQalmS4TAMAQBEII6Vwp/b6TVINGmfnXgAAikAYKUWwRgotkiS1WBEN0jMCAEDBCCOlcjfLW6KI3onSMwIAQKEII6VyL9UstqIaiE54XAwAAPMPYaRU7oyaFiuq42MJxZO2xwUBADC/EEZKlV74zHIXPmN6LwAABSGMlMoNI2eGxySJcSMAABSIMFKqzP40zmZ5AxHCCAAAhSCMlCp9mcbnXKZ5h7VGAAAoCGGkVO5smmZ3fxou0wAAUBjCSKncyzSNtrM/DdN7AQAoDGGkVO5lmvrkCUn0jAAAUCjCSKncMBJMjSmsOGEEAIACEUZKVdMk+QKSpMWKMoAVAIACEUZKZVmZ3pElVlQDkZiMMR4XBQDA/EEYKYes/WliSVvRWNLjggAAmD8II+Xg7tx7ZnBUEoNYAQAoBGGkHNzpve0sCQ8AQMEII+XgXqY5I+T0jAwQRgAAyBthpBzcAaxtfmd/GnpGAADIH2GkHNzLNEusiCTCCAAAhSCMlEPDcknSYvuYJJaEBwCgEISRcljkhJGGxKAkekYAACgEYaQc3J6R2tigJEMYAQCgAISRcljUJkny2Qk1a0SDLAkPAEDeCCPlEAhJtc7CZ23WcQ2NxpVM2R4XBQDA/EAYKZeGMyRJbdYJGSMNjcY9LggAgPmBMFIuDc6lmnfXRiUxiBUAgHwRRsrF7RlZHSKMAABQCMJIubiDWM8MOAufsdYIAAD5IYyUizu9t806LomeEQAA8kUYKRc3jCwxhBEAAApBGCkXdxXWxuSQJOkd1hoBACAvhJFycWfT1MXekWQ0ECGMAACQD8JIubg9I347rkaN0jMCAECeCCPlEqyRapolScusE4wZAQAgT0WFkV27dqmjo0M1NTXq7OzUvn37Zj23v79f11xzjd73vvfJ5/Npy5YtxdY692XNqBmLpzQSS3pcEAAAc1/BYWTPnj3asmWLtm/frgMHDujSSy/VFVdcod7e3hnPj8ViWrp0qbZv367zzjuv5ILnNDeMrHTXGqF3BACAUys4jNx77726/vrrdcMNN2jt2rW677771N7ert27d894/rve9S595Stf0aZNm9TU1FRywXOaO26kI8wqrAAA5KugMBKPx9XT06Ourq6c411dXdq/f3/ZiorFYopEIjm3ecHtGWkPDksijAAAkI+Cwsjg4KBSqZTa2tpyjre1teno0aNlK2rnzp1qamrK3Nrb28v22hXlhpHlPieMsCQ8AACnVtQAVsuycu4bY6YdK8W2bds0PDycufX19ZXttSvK3Z+m1RyTRM8IAAD5CBRycmtrq/x+/7RekIGBgWm9JaUIh8MKh8Nle72qcXfubUoRRgAAyFdBPSOhUEidnZ3q7u7OOd7d3a2LLrqorIXNS+4qrIsSQ5IMC58BAJCHgnpGJGnr1q269tprtX79em3YsEEPPvigent7tXnzZknOJZYjR47o0UcfzTzn4MGDkqSRkRG98847OnjwoEKhkN7//veX51PMFe5smkBqXA0aZ0l4AADyUHAY2bhxo4aGhrRjxw719/dr3bp12rt3r1avXi3JWeRs6poj559/fub7np4ePf7441q9erXeeOON0qqfa0J1UrhJig1rmXVc74ws9roiAADmvILDiCTddNNNuummm2Z87JFHHpl2zBhTzNvMTw1tbhg5ocMjMaVsI7+vfIN7AQA43bA3Tbm5M2rarOOyjXRsNO5xQQAAzG2EkXJzZ9S8y12F9RcR1hoBAOBkCCPl5s6oWR0akSS9fWLcy2oAAJjzCCPl5vaMrAyckCS9dZwwAgDAyRBGys0dM7LMOiGJMAIAwKkQRsrN3Z9mcWpIkvTW8TEvqwEAYM4jjJSbe5mmLu6EkT56RgAAOKmi1hnBSbiXaQLJUdVrXG8dp4kBADgZekbKLbxICi2S5IwbiU4kNTye8LgoAADmLsJIJbjjRt5T60zvZdwIAACzI4xUgrth3vvqRyVJfccYNwIAwGwII5XgLnzW4a7CSs8IAACzI4xUgjuj5sxgRBJrjQAAcDKEkUpIL3ymE5IIIwAAnAxhpBLcnhEWPgMA4NQII5Xgjhmpjw9KcnpGjDFeVgQAwJxFGKkEdzZNcPwXkqSRGGuNAAAwG8JIJbjrjFixqM6sdw4xbgQAgJkRRioh3CAF6yRJ5zQ5IYRxIwAAzIwwUgmWJTWukCSdXXdCEgufAQAwG8JIpSx5ryTpfYGjkugZAQBgNoSRSml1wsgqc0QSY0YAAJgNYaRSWn9JkrQs1iuJMAIAwGwII5XihpGGkcOSpL7jY6w1AgDADAgjleJepgmOHFGtJjQWT+n4GGuNAAAwFWGkUupapLolkqTORSwLDwDAbAgjleRequmsm1wWHgAA5CKMVJJ7qWZtkOm9AADMhjBSSW7PyGo503tZ+AwAgOkII5XkhpHl8T5J9IwAADATwkglLXmPJKlx7A1ZshkzAgDADAJeF3Baa14t+UPyp2I60xrSW8eDMsbIsiyvKwMAYM6gZ6SS/AGp5d2SpHdbb2s8kdLQaNzjogAAmFsII5Xmzqg5r/YdSUzvBQBgKsJIpbmDWNeFmN4LAMBMCCOV5vaMdFhvS6JnBACAqQgjleaGkTMSzvTevmP0jAAAkI0wUmlLnDCyKDGkBo2plzACAEAOwkil1TRKDWdIks6y3tYrb0dkjPG4KAAA5g7CSDW4l2reFziqY6Nx/Xxw1OOCAACYOwgj1eBeqtnQOCRJevGNY15WAwDAnEIYqQZ3eu/ZoV9Ikl5847iX1QAAMKcQRqrBvUxzZsqZUdPzJmEEAIA0wkg1uD0jdSO98iulnw+OanAk5nFRAADMDYSRamg8UwrWybIT+lCrM7WX3hEAAByEkWrw+aQl75EkfaTVCSEMYgUAwEEYqRZ33Mj5dc6GeS/SMwIAgCTCSPW440Y65OxR85Mjw5pIpLysCACAOYEwUi1uGKkffFnLGsJKpIxe7jvhbU0AAMwBhJFqOevDki8oa+BVfeqME5K4VAMAgEQYqZ66Fum9l0uSfs33Q0kMYgUAQCKMVNc5n5UkrR38jizZ6nnzuGybTfMAAAsbYaSa3neFFGpQaOQtXRT8X0UmkvrZOyNeVwUAgKcII9UUrJXWfkqS9DuNz0uSXuBSDQBggSOMVNu5zqWai2P7FFRSPWyaBwBY4Agj1dZxmbSoTbXJiD7ke1kvvEnPCABgYSOMVJvPL637jCTpKv8P1XdsXAORCY+LAgDAO4QRL7izai73H1C9xvV3L/Z5XBAAAN4hjHhhxfnSkveoRjF93PeCvvrMz/SzAWbVAAAWJsKIFyxLOuc3JUm/0/iC4klbd377v1lzBACwIBFGvHLO/5EkrYsd0HmhI3rxzeN67MdvelwUAADVRxjxypJ3S6s2yDK2nvJv0xcCT+qr/35Qbx0f87oyAACqijDipc98Q3pvl/wmqZsCT+ufra36x2/tlrFtrysDAKBqLGPMnB+oEIlE1NTUpOHhYTU2NnpdTnkZI/3Pvyvxb3+sYPQtSdJ4oEm+umYF65rlq22SapqkRW3SouVSQ9bXhhVS3RLJR6YEAMw9+f7+DlSxJszEsqQ1n1DwrA/rhW/9X537xiOqTQ5LkWEpcuoxJLYVUKJ2qcyi5fLXL5a/bvFkgAk3SuGGyVtokRReJIXSxxZJwXrCDADAU/SMzCHJlK2HvntQr7/+/3T82KDsiYgaNKZma0RLrWEt0wkts45rmXVCy6wTWqKIfFbpP76Ev1bJQJ3sQL1SgTqZYL3sYJ0UqpeCdbJC9fKF6mSF6+QP1cofqlcgXOscC9ZKwTopWCMFsm9hZy+e9H1/0AleAIAFI9/f34SROezYaFw/GxhR37ExTSRTmkjYirlfI+MJDUVGlRw+KmukX8GxAQWTUTVqTI3WqJo0qkUaV701oUUa1yJrPOd+vSYUsKo3NsWWT3ErpGT65gsp5QsqZYVk+0KyfUHZ/pBsy/lq/CEZXzDzVYGwjD8k+UOSPywrEJT8IVn+kBQIy/IHZQVCsvxB+QIh+QJB+fwh53t/QL5AUP5gSD5/UFYgKJ8/LH/QOccfCCoQDMrvPp/QBADlwWWa00BLfUgf7GjRBzta8jo/kbJ1YiyhE2NxHRuNaySW1ETC1mAypbcStsYTKU0kUhqLJzUeSykZH5U9EZXiY1JiVD73FkiOK5gaUyA1rpDt3AJ2TEF7QiETV50VU43iqlFcYSuhWjn3w0qoxnK/Kq4aK5GpzSdbNWZCMu7S96lKtFh5JI1PSfmVVMD5avmVknOz5VfKvW8sn3PM8suWT7blk5FftuWTnT5u+WXcW/b99OOyfDKWT2bK98bySZbfuYTmPif9uHPcue/cLOeYZUmyZCyfLMuSsfyyfD4ZX8B93L3vvobls2RZflnp5/uc1/NZlvteliz3PSzL5z7XeQ3JkuVznmv5nPdOP8/nsyT5JJ9Tj+XWI8vnPMf9TD7Lcj6HLMnnkyVLlk8y7mOW+1qWfLJ8kwHRecz92LLks7Lzo5X53pKc+jR5buYxK/cx95mSJCPn77P0n2k+K/0elvy+mZ+jTD3p13ceSdcqKSfjpp8303My51iTx4HTXVFhZNeuXfrrv/5r9ff36+yzz9Z9992nSy+9dNbzn332WW3dulWvvPKKVqxYoS984QvavHlz0UVjZkG/T0sbwlraEK7Ye9i2USxpK560FUulFEvYiqec+yeSzveJpK1YylYikZKdjMmOj8kkJmTi47JTMZlETCY5IZN0vlcqJqUSUjIuKxWT7IR8qZh8dkKWHZcvFZdlJ+SzE/LbcflNXH47KZ9JyG+S8tsJBUxCfiXlN0kFTFJ+k5BfthMnTEoBJRVQ9teUgkrNeJkrYNkKyJaUmN4AkmSmfEXV2MaSkWRkubfs7y3ZsmTLN+NxkwkbkjT7L/iUfJnXcd5v5nNnev+pxybfz3nP3Md1ytee+rz0Z5v8BFbWcybPlSRjpf8jGSv3c0zWlolCubVa2cesaa9t5XzCrDotycg3YzvkVpvzFjN89vTzprdj9hGfjGSln+OEZPskP1ul29HyOa9jTO6ntLLe2w336apyX2OmGqf+xCTLMjk/sXSbpGu0MkcnP7sk548SZb9/Opy6P4kpFzRMplZrsj2M+55umPWZlNNKJiWfjFNH+g8gObcVl/2Ozv+Vj5yk/Sqn4DCyZ88ebdmyRbt27dLFF1+sBx54QFdccYVeffVVrVq1atr5hw8f1ic+8Qn93u/9nh577DH98Ic/1E033aSlS5fqM5/5TFk+BKrH57NUG/KrNuSXFPS6nKIYY2QbKWHbspMpJZMxpZIJ9xaXnUzIpBIyyYRMKqlUMi5jp5RK3085900q6dzS35ukLDuVuS+TlEnZMiYppZIytvO4ZVKSnXRuxpZlbMmkJDvlfDW2jG275znHLGPcr6nMcywZydju/ZRksn4FZM5JyWennP/9ua/jfG9kafI56dezTCrrf87p84zz69nYmV/T6ePpxzTD/9hzfz1LfpV+WXAyPFYpCc73Tolq11/oj4VAP6e8OHSpJG/CSMFjRi688EJdcMEF2r17d+bY2rVrddVVV2nnzp3Tzr/jjjv09NNP67XXXssc27x5s15++WX96Ec/yus9F+qYEeC0YyYDlOyUlBWonJtxj5nc79O/taYeyznfznq9GY5lPz/z/bQCJ2tzA2Bu74MTZGWMTOa1jYx7S7+3cR83UuZ+5lw3uDnHLBmZKaUYGTtd5+TrOyfZmTLTXyafa2fu5Lxf5rnKHJs8J/tHk/UXelbt1tS2z/pbfrLXw3kfy/186XOtrO+N8yd7+lPN2PTp11FW2+b255jJ3gjLknF7yqzM+9uTbTTDa2fqMvaU3gS3Nyfdxib9s7JluctxZfcKTf5bnWxz98HMN+montPv4T7Haaes64mZPpLJ17aMnfXMbFOu+6XbN+vfvGVZuT87Scbnk3P51D/53nbKfb+UZNtq/OWNWvqezpl+OkWryJiReDyunp4e3XnnnTnHu7q6tH///hmf86Mf/UhdXV05xz7+8Y/roYceUiKRUDA4/a/rWCymWCyW82EAnAbS41Pkd2ZYzTOWJL/XRQCnoYIWmBgcHFQqlVJbW1vO8ba2Nh09enTG5xw9enTG85PJpAYHB2d8zs6dO9XU1JS5tbe3F1ImAACYR4pa7Wrq6G5jzElHfM90/kzH07Zt26bh4eHMra+vr5gyAQDAPFDQZZrW1lb5/f5pvSADAwPTej/Sli9fPuP5gUBAS5YsmfE54XBY4XDlZoQAAIC5o6CekVAopM7OTnV3d+cc7+7u1kUXXTTjczZs2DDt/O985ztav379jONFAADAwlLwZZqtW7fqG9/4hr75zW/qtdde0+23367e3t7MuiHbtm3Tpk2bMudv3rxZb775prZu3arXXntN3/zmN/XQQw/pj/7oj8r3KQAAwLxV8DojGzdu1NDQkHbs2KH+/n6tW7dOe/fu1erVqyVJ/f396u3tzZzf0dGhvXv36vbbb9f999+vFStW6Ktf/SprjAAAAEnsTQMAACok39/f7B0PAAA8RRgBAACeIowAAABPEUYAAICnCCMAAMBThBEAAOCpgtcZ8UJ69jG79wIAMH+kf2+fahWReRFGotGoJLF7LwAA81A0GlVTU9Osj8+LRc9s29bbb7+thoaGk+4OXKhIJKL29nb19fWxmFqF0dbVRXtXD21dPbR19ZSrrY0xikajWrFihXy+2UeGzIueEZ/Pp5UrV1bs9RsbG/mHXSW0dXXR3tVDW1cPbV095Wjrk/WIpDGAFQAAeIowAgAAPLWgw0g4HNZdd92lcDjsdSmnPdq6umjv6qGtq4e2rp5qt/W8GMAKAABOXwu6ZwQAAHiPMAIAADxFGAEAAJ4ijAAAAE8t6DCya9cudXR0qKamRp2dndq3b5/XJc17O3fu1C//8i+roaFBy5Yt01VXXaX/+Z//yTnHGKO7775bK1asUG1trT784Q/rlVde8aji08POnTtlWZa2bNmSOUY7l9eRI0f0uc99TkuWLFFdXZ0+8IEPqKenJ/M47V0eyWRSf/qnf6qOjg7V1tbqrLPO0o4dO2TbduYc2ro4P/jBD/SpT31KK1askGVZ+qd/+qecx/Np11gspltvvVWtra2qr6/Xr/3ar+mtt94qvTizQD355JMmGAyar3/96+bVV181t912m6mvrzdvvvmm16XNax//+MfNww8/bH7yk5+YgwcPmiuvvNKsWrXKjIyMZM655557TENDg/n2t79tDh06ZDZu3GjOOOMME4lEPKx8/nr++efNu971LnPuueea2267LXOcdi6fY8eOmdWrV5vPf/7z5sc//rE5fPiw+e53v2t+9rOfZc6hvcvjL/7iL8ySJUvMv/7rv5rDhw+bv//7vzeLFi0y9913X+Yc2ro4e/fuNdu3bzff/va3jSTzj//4jzmP59OumzdvNmeeeabp7u42L730kvnIRz5izjvvPJNMJkuqbcGGkQ9+8INm8+bNOcfWrFlj7rzzTo8qOj0NDAwYSebZZ581xhhj27ZZvny5ueeeezLnTExMmKamJvO1r33NqzLnrWg0at773vea7u5uc9lll2XCCO1cXnfccYe55JJLZn2c9i6fK6+80vzu7/5uzrFPf/rT5nOf+5wxhrYul6lhJJ92PXHihAkGg+bJJ5/MnHPkyBHj8/nMf/zHf5RUz4K8TBOPx9XT06Ourq6c411dXdq/f79HVZ2ehoeHJUktLS2SpMOHD+vo0aM5bR8Oh3XZZZfR9kW4+eabdeWVV+pjH/tYznHaubyefvpprV+/Xp/97Ge1bNkynX/++fr617+eeZz2Lp9LLrlE//Vf/6Wf/vSnkqSXX35Zzz33nD7xiU9Ioq0rJZ927enpUSKRyDlnxYoVWrduXcltPy82yiu3wcFBpVIptbW15Rxva2vT0aNHParq9GOM0datW3XJJZdo3bp1kpRp35na/s0336x6jfPZk08+qZdeekkvvPDCtMdo5/L6+c9/rt27d2vr1q36kz/5Ez3//PP6wz/8Q4XDYW3atIn2LqM77rhDw8PDWrNmjfx+v1KplL74xS/q6quvlsS/7UrJp12PHj2qUCikxYsXTzun1N+dCzKMpFmWlXPfGDPtGIp3yy236L//+7/13HPPTXuMti9NX1+fbrvtNn3nO99RTU3NrOfRzuVh27bWr1+vv/zLv5QknX/++XrllVe0e/dubdq0KXMe7V26PXv26LHHHtPjjz+us88+WwcPHtSWLVu0YsUKXXfddZnzaOvKKKZdy9H2C/IyTWtrq/x+/7QkNzAwMC0Voji33nqrnn76aX3ve9/TypUrM8eXL18uSbR9iXp6ejQwMKDOzk4FAgEFAgE9++yz+upXv6pAIJBpS9q5PM444wy9//3vzzm2du1a9fb2SuLfdTn98R//se6880791m/9ls455xxde+21uv3227Vz505JtHWl5NOuy5cvVzwe1/Hjx2c9p1gLMoyEQiF1dnaqu7s753h3d7cuuugij6o6PRhjdMstt+ipp57SM888o46OjpzHOzo6tHz58py2j8fjevbZZ2n7Anz0ox/VoUOHdPDgwcxt/fr1+u3f/m0dPHhQZ511Fu1cRhdffPG0Keo//elPtXr1akn8uy6nsbEx+Xy5v5r8fn9mai9tXRn5tGtnZ6eCwWDOOf39/frJT35SetuXNPx1HktP7X3ooYfMq6++arZs2WLq6+vNG2+84XVp89of/MEfmKamJvP973/f9Pf3Z25jY2OZc+655x7T1NRknnrqKXPo0CFz9dVXMy2vDLJn0xhDO5fT888/bwKBgPniF79oXn/9dfOtb33L1NXVmcceeyxzDu1dHtddd50588wzM1N7n3rqKdPa2mq+8IUvZM6hrYsTjUbNgQMHzIEDB4wkc++995oDBw5klrTIp103b95sVq5cab773e+al156yfzqr/4qU3tLdf/995vVq1ebUChkLrjggsz0UxRP0oy3hx9+OHOObdvmrrvuMsuXLzfhcNh86EMfMocOHfKu6NPE1DBCO5fXv/zLv5h169aZcDhs1qxZYx588MGcx2nv8ohEIua2224zq1atMjU1Neass84y27dvN7FYLHMObV2c733vezP+//m6664zxuTXruPj4+aWW24xLS0tpra21nzyk580vb29JddmGWNMaX0rAAAAxVuQY0YAAMDcQRgBAACeIowAAABPEUYAAICnCCMAAMBThBEAAOApwggAAPAUYQQAAHiKMAIAADxFGAEAAJ4ijAAAAE8RRgAAgKf+Px1vrDi77QBKAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
